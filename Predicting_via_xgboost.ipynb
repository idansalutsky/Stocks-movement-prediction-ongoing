{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Notebook Summary\n",
        "We will select features by using the addition of the L1 norm to the loss of the LSTM network, thus we will get the more important features by checking the absolute value of the weights.\n",
        "Finally, I re-ran the network on the reduced features, the accuracy improved in the weekly and monthly forecast, but we will note that this network was not only designed to adjust the weights to the information because of the loss, therefore we will take the results with limited responsibility and later on in the project I will use the features I found here to run the forecasting algorithm"
      ],
      "metadata": {
        "id": "R_vNiQcGI11d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###results\n",
        "The results of the model are not good, but we will notice that the longer the prediction range is, the model gives less good performances"
      ],
      "metadata": {
        "id": "O5NlOEe2Xw7X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqPZcLuXTkBV",
        "outputId": "93052b1e-a8a3-43a4-9d1d-f275a2b18ab4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vVkQGQsDqMUj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "Consecutive_stocks =  pd.read_csv('/content/drive/MyDrive/stocks_data/Consecutive_stocks.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_df = pd.read_csv('/content/drive/MyDrive/stocks_data/selected_columns.csv')\n",
        "\n",
        "# Retrieve lists from loaded DataFrame\n",
        "columns_to_use_day = loaded_df['columns_to_use_day'].tolist()\n",
        "columns_to_use_week = loaded_df['columns_to_use_week'].tolist()\n",
        "columns_to_use_month = loaded_df['columns_to_use_month'].tolist()"
      ],
      "metadata": {
        "id": "uQOVrUo1LA_Z"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "9w1H1Dev78vl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    confusion_matrix, classification_report\n",
        ")\n",
        "from datetime import datetime, timedelta\n",
        "from sklearn.utils import resample\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "\n",
        "def xgb_pipline(label_type = 'label_week', df = pd.DataFrame(),columns_to_use = [],start_date = '2021-12-31', alpha = 0.8):\n",
        "\n",
        "    print(f\"Preprocessing... label-{label_type}, split train, val and test, scalling features and resample train to get equally number of samples for each class\")\n",
        "    df = df.copy()\n",
        "    df.reset_index(drop=True,inplace=True)\n",
        "    df.rename(columns={label_type: 'y'}, inplace=True)\n",
        "\n",
        "    # Exclude some columns from the 'df' DataFrame\n",
        "    if label_type == 'label_week':\n",
        "        columns_to_exclude = ['label_day', 'y', 'label_month', 'Symbol', 'date','pct_change_week','pct_change_month', 'stock']\n",
        "    elif label_type == 'label_day':\n",
        "        columns_to_exclude = ['y', 'label_week', 'label_month', 'Symbol', 'date','pct_change_week','pct_change_month', 'stock']\n",
        "    elif label_type == 'label_month':\n",
        "        columns_to_exclude = ['label_day', 'label_week', 'y', 'Symbol', 'date','pct_change_week','pct_change_month', 'stock']\n",
        "    else:\n",
        "        columns_to_exclude = ['label_day', 'label_week', 'label_month', 'y', 'Symbol', 'date','pct_change_week','pct_change_month', 'stock']\n",
        "\n",
        "    all_columns = df.columns\n",
        "    columns_to_exclude = list(set(all_columns) - set(columns_to_use+['y']))\n",
        "\n",
        "    df_without_labels = df.drop(columns=columns_to_exclude)\n",
        "    best_features = columns_to_use\n",
        "    labels = 'y'\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    df[best_features] = scaler.fit_transform(df[best_features])\n",
        "    # Split the data into training and validaition  and test sets\n",
        "    df_model = df[df['y'].isna()==False]\n",
        "    df_model.reset_index(drop=True,inplace=True)\n",
        "\n",
        "    df_model['date'] = pd.to_datetime(df_model['date'])\n",
        "\n",
        "    df_model = df_model[df_model['date']>start_date]\n",
        "    latest_date = df_model['date'].max()\n",
        "    first_date = df_model['date'].min()\n",
        "    num_days = (latest_date - first_date).days\n",
        "    split_date = first_date + pd.DateOffset(days=int(alpha * num_days))\n",
        "\n",
        "    End_Train_date = split_date\n",
        "    Start_test_date = split_date\n",
        "\n",
        "\n",
        "    train_data = df_model[df_model['date'] < End_Train_date]\n",
        "    train_data = train_data.sort_values(by=['Symbol','date'])\n",
        "\n",
        "    test_data  = df_model[df_model['date'] >= Start_test_date]\n",
        "    class_counts = train_data[labels].value_counts()\n",
        "\n",
        "    X_train = train_data[best_features]\n",
        "    y_train = train_data[labels]\n",
        "    X_test = test_data[best_features]\n",
        "    y_test = test_data[labels]\n",
        "\n",
        "    # hanadlling labels imblance by resamleing equally\n",
        "    min_class_count = train_data['y'].value_counts().min()\n",
        "\n",
        "    train_data = pd.concat([\n",
        "        resample(train_data[train_data['y'] == cls].sort_values('date', ascending=False),\n",
        "                replace=False,\n",
        "                n_samples=min_class_count,\n",
        "                random_state=42)\n",
        "        for cls in train_data['y'].unique()\n",
        "    ])\n",
        "\n",
        "    print('Start training')\n",
        "    model = XGBClassifier(enable_categorical = True,objective='multi:softprob', reg_alpha=0.1,reg_lambda = 0.1)\n",
        "    model.fit(X_train, y_train.values.ravel())\n",
        "\n",
        "    class_labels = sorted(df[labels].unique())\n",
        "\n",
        "    proba_predictions = model.predict_proba(X_test)\n",
        "    proba_predictions1 = proba_predictions.copy()\n",
        "\n",
        "    y_pred = proba_predictions1.argmax(axis=1)\n",
        "    proba_predictions = proba_predictions.max(axis=1)\n",
        "\n",
        "    # Evaluate the classifier\n",
        "    print('Evaluating')\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "    report = classification_report(y_test, y_pred)\n",
        "    unique_classes = list(set(y_test))\n",
        "    cm = confusion_matrix(y_test, y_pred, labels=unique_classes)\n",
        "\n",
        "    print(f'Accuracy {accuracy* 100:.2f}')\n",
        "    print(f'F1-{f1}')\n",
        "    print(f'report-')\n",
        "    print(report)\n",
        "    print('confusion_matrix-')\n",
        "    print(cm)\n",
        "\n",
        "    return model,accuracy, f1, report,cm\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_test_ratio=0.8\n",
        "start_date='2021-12-31'"
      ],
      "metadata": {
        "id": "9AnoT5VewlvY"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Day"
      ],
      "metadata": {
        "id": "2F1tzXXc7V_D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_day,accuracy_day, f1_day, report_day,cm_day  = xgb_pipline(label_type = 'label_day', df = Consecutive_stocks, columns_to_use = columns_to_use_day,start_date = start_date, alpha = train_test_ratio)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSA6qeXn1moI",
        "outputId": "8c30588b-1a6e-46e6-c29e-66489ad95d2c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing... label-label_day, split train, val and test, scalling features and resample train to get equally number of samples for each class\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-74a18241a0ec>:45: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_model['date'] = pd.to_datetime(df_model['date'])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training\n",
            "Evaluating\n",
            "Accuracy 36.05\n",
            "F1-0.31234283348407316\n",
            "report-\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.11      0.03      0.05      2934\n",
            "         1.0       0.11      0.02      0.03     14619\n",
            "         2.0       0.13      0.02      0.03     39282\n",
            "         3.0       0.35      0.30      0.32    159159\n",
            "         4.0       0.39      0.64      0.48    171547\n",
            "         5.0       0.13      0.03      0.05     36074\n",
            "         6.0       0.08      0.03      0.05     15637\n",
            "         7.0       0.09      0.01      0.02      4735\n",
            "\n",
            "    accuracy                           0.36    443987\n",
            "   macro avg       0.17      0.14      0.13    443987\n",
            "weighted avg       0.30      0.36      0.31    443987\n",
            "\n",
            "confusion_matrix-\n",
            "[[    83    143    123    705   1576    116    137     51]\n",
            " [    62    303    467   3705   8923    461    606     92]\n",
            " [    62    334    720  11085  25165    955    883     78]\n",
            " [   168    494   1308  47752 105539   2327   1470    101]\n",
            " [   177    573   1546  54971 109512   2958   1679    131]\n",
            " [    68    342    720  12782  20191   1143    766     62]\n",
            " [    60    355    482   5542   8139    488    508     63]\n",
            " [    58    225    235   1396   2420    171    174     56]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Week"
      ],
      "metadata": {
        "id": "F78D4JNV7YkV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_week,accuracy_week, f1_week, report_week, cm_week = xgb_pipline(label_type = 'label_week', df = Consecutive_stocks, columns_to_use = columns_to_use_week,start_date = start_date, alpha = train_test_ratio)\n"
      ],
      "metadata": {
        "id": "Jj_5KVeg2XDS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a4df05f-4fa6-420b-f7ac-922895434f5d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing... label-label_week, split train, val and test, scalling features and resample train to get equally number of samples for each class\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-74a18241a0ec>:45: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_model['date'] = pd.to_datetime(df_model['date'])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training\n",
            "Evaluating\n",
            "Accuracy 22.47\n",
            "F1-0.19860980733459133\n",
            "report-\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.17      0.22      0.19     22285\n",
            "         1.0       0.16      0.24      0.19     47412\n",
            "         2.0       0.20      0.11      0.14     58020\n",
            "         3.0       0.25      0.35      0.29     89802\n",
            "         4.0       0.27      0.41      0.32     96108\n",
            "         5.0       0.12      0.02      0.03     54450\n",
            "         6.0       0.15      0.05      0.07     44959\n",
            "         7.0       0.21      0.12      0.16     26754\n",
            "\n",
            "    accuracy                           0.22    439790\n",
            "   macro avg       0.19      0.19      0.17    439790\n",
            "weighted avg       0.20      0.22      0.20    439790\n",
            "\n",
            "confusion_matrix-\n",
            "[[ 4811  6104  1275  2581  2993   507  1302  2712]\n",
            " [ 4298 11249  4891 11480 10177   889  2044  2384]\n",
            " [ 2945  9555  6126 18708 16438  1096  1620  1532]\n",
            " [ 3352 11207  7116 31275 31950  1619  1840  1443]\n",
            " [ 3504 11638  5560 31306 38940  1526  2070  1564]\n",
            " [ 2299  7836  2642 15881 21994   933  1700  1165]\n",
            " [ 3175  7772  1638 11014 16632   776  2163  1789]\n",
            " [ 4568  6051   713  3682  6265   430  1722  3323]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Month"
      ],
      "metadata": {
        "id": "yOSMRS0T7aqm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_month,accuracy_month, f1_month, report_month, cm_month =  xgb_pipline(label_type = 'label_month', df = Consecutive_stocks, columns_to_use = columns_to_use_month,start_date = start_date, alpha = train_test_ratio)\n"
      ],
      "metadata": {
        "id": "Wgl7ZBxO2oOy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4beff8fe-262f-4beb-dfe7-4af4b305eb89"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing... label-label_month, split train, val and test, scalling features and resample train to get equally number of samples for each class\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-74a18241a0ec>:45: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_model['date'] = pd.to_datetime(df_model['date'])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training\n",
            "Evaluating\n",
            "Accuracy 19.51\n",
            "F1-0.17318391734898014\n",
            "report-\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.28      0.40      0.33     93997\n",
            "         1.0       0.09      0.09      0.09     60496\n",
            "         2.0       0.07      0.01      0.02     35736\n",
            "         3.0       0.16      0.07      0.09     36239\n",
            "         4.0       0.20      0.12      0.15     37715\n",
            "         5.0       0.08      0.02      0.03     29267\n",
            "         6.0       0.09      0.11      0.10     46637\n",
            "         7.0       0.21      0.31      0.25     91511\n",
            "\n",
            "    accuracy                           0.20    431598\n",
            "   macro avg       0.15      0.14      0.13    431598\n",
            "weighted avg       0.17      0.20      0.17    431598\n",
            "\n",
            "confusion_matrix-\n",
            "[[37848  3451   182   791  1800   939  9074 39912]\n",
            " [15486  5325   465  1863  3921  1615 12631 19190]\n",
            " [ 8034  4108   383  1836  2844  1234  7668  9629]\n",
            " [ 8040  5086   426  2433  3345  1042  6787  9080]\n",
            " [ 8609  6155   574  2536  4396   860  5612  8973]\n",
            " [ 7272  6075   574  1688  1922   572  4168  6996]\n",
            " [12860 11011  1184  2273  2131   642  5317 11219]\n",
            " [36344 16046  2020  2038  1732   658  4739 27934]]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}