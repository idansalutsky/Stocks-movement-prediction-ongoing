{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqPZcLuXTkBV",
        "outputId": "3a7a5a39-aa99-481e-a358-08aa37d11354"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fmcqT45BpCa"
      },
      "outputs": [],
      "source": [
        "!wget http://prdownloads.sourceforge.net/ta-lib/ta-lib-0.4.0-src.tar.gz\n",
        "!tar -xzvf ta-lib-0.4.0-src.tar.gz\n",
        "%cd ta-lib\n",
        "!./configure --prefix=/usr\n",
        "!make\n",
        "!make install\n",
        "!apt-get install libatlas-base-dev\n",
        "!pip install TA-Lib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S2_eMoACgl58"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "measures_tickers = ['^GSPC', '^VIX']\n",
        "all_symbols = stock_info_df_symbols#replace with list of stocks tickers\n",
        "\n",
        "End_date = (datetime.today() + timedelta(days=1)).strftime('%Y-%m-%d')\n",
        "Start_date = (datetime.today() - timedelta(days=4*365)).strftime('%Y-%m-%d')\n",
        "print(Start_date)\n",
        "data = yf.download(all_symbols + measures_tickers , start=Start_date, end=End_date)\n",
        "data.dropna(axis=0,inplace=True,how=\"all\")\n",
        "data.dropna(axis=1,inplace=True,how=\"all\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YyL3k1xU0E0g"
      },
      "outputs": [],
      "source": [
        "#################### EXTRACT FROM YF INDUSTRY AND SECTOR FOR each stock\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "\n",
        "# List of stock tickers\n",
        "stock_tickers = all_symbols\n",
        "\n",
        "# Create an empty DataFrame to store the information\n",
        "stock_info_df = pd.DataFrame(columns=['Ticker', 'Industry', 'Sector'])\n",
        "\n",
        "# Loop through each stock ticker\n",
        "for ticker in stock_tickers:\n",
        "    try:\n",
        "        # Get information from Yahoo Finance\n",
        "        stock = yf.Ticker(ticker)\n",
        "        info = stock.info\n",
        "\n",
        "        # Extract industry and sector information\n",
        "        industry = info.get('industry', 'N/A')\n",
        "        sector = info.get('sector', 'N/A')\n",
        "\n",
        "        # Append information to the DataFrame\n",
        "        stock_info_df = pd.concat([stock_info_df, pd.DataFrame({'Symbol': [ticker], 'Industry': [industry], 'Sector': [sector]})], ignore_index=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching data for {ticker}: {e}\")\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "stock_info_df.to_csv('/content/drive/MyDrive/stocks_data/stock_industrySector.csv', index=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_r5dLNnji7V"
      },
      "outputs": [],
      "source": [
        "industry_dict = {industry: group['Symbol'].tolist() for industry, group in stock_info_df.groupby('Industry')}\n",
        "sector_dict = {industry: group['Symbol'].tolist() for industry, group in stock_info_df.groupby('Sector')}\n",
        "stock_info_df.set_index('Symbol', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTL9XF8a9CHt"
      },
      "outputs": [],
      "source": [
        "from numpy.ma.core import equal\n",
        "import talib as tb\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "def preprocess_sentiment(df, start_time, end_time,measures_tickers,stocks_list,industry_dict,sector_dict,all_stocks_data):\n",
        "     \"\"\"\n",
        "    Preprocesses stocks data to achive market sentimant\n",
        "\n",
        "    Args:\n",
        "        df (DataFrame): The input DataFrame containing sentiment data.\n",
        "        start_time (str): The starting date for considering data in the preprocessing.\n",
        "        end_time (str): The ending date for considering data in the preprocessing.\n",
        "        measures_tickers (list): List of tickers for sentiment measures.\n",
        "        stocks_list (list): List of stock tickers to consider.\n",
        "        industry_dict (dict): Dictionary mapping stock tickers to industry names.\n",
        "        sector_dict (dict): Dictionary mapping stock tickers to sector names.\n",
        "        all_stocks_data (DataFrame): Additional information about all stocks.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing two elements - processed DataFrame (`df`) and a list of removed stock tickers (`removed_stocks`).\n",
        "\n",
        "    The preprocess_sentiment function takes  data in the form of a DataFrame, along with\n",
        "    additional parameters. It calculates various percentage changes and ratios\n",
        "    based on the provided measures, groups, and frames.\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "    measures_tickers=['^GSPC']\n",
        "    short_ind = 26\n",
        "    #medium_ind = 50\n",
        "    long_ind = 100\n",
        "\n",
        "    # Define the intervals for weekly and monthly data\n",
        "    frames = [short_ind, long_ind]\n",
        "    group_dict = {}\n",
        "    removed_stocks = []\n",
        "    for i, stock in enumerate(stocks_list):\n",
        "        if stock in measures_tickers or stock not in df['Adj Close'].columns:\n",
        "          print('in',stock)\n",
        "          removed_stocks.append(stock)\n",
        "          continue\n",
        "        Industry = all_stocks_data.loc[stock, 'Industry']\n",
        "        #print(Industry,stock)\n",
        "        Sector = all_stocks_data.loc[stock, 'Sector']\n",
        "        groups = ['Industry']\n",
        "\n",
        "        adj_close_stock = df['Adj Close', stock]\n",
        "        volume_stock = df[f'Volume'][stock]\n",
        "\n",
        "        for frame in frames:\n",
        "            df[f'pct_change_{frame}', stock] = adj_close_stock.pct_change(periods=frame)\n",
        "\n",
        "            for measure in measures_tickers:#measures calc\n",
        "                measure_adj_close = df['Adj Close'][measure]\n",
        "\n",
        "                df[f'pct_change_{frame}_{measure}', stock] = measure_adj_close.pct_change(periods=frame)\n",
        "\n",
        "            for group in groups:#groups calc\n",
        "                if group == 'Industry':\n",
        "                    group_list = industry_dict[Industry]\n",
        "                else:\n",
        "                    group_list = sector_dict[Sector]\n",
        "                #group_list = ['A','AA'] #need to change\n",
        "                if (group,frame) in group_dict.keys():\n",
        "                    df[f'pct_change_{frame}_{group}', stock] = group_dict[(group,frame)]\n",
        "                else:\n",
        "                    df[f'pct_change_{frame}_{group}', stock] = df['Adj Close'][group_list].pct_change(periods=frame).mean(axis=1, )\n",
        "                    group_dict[(group,frame)] = list(df[f'pct_change_{frame}_{group}', stock])\n",
        "\n",
        "            #for group in groups:#ratios with the stock and indexes\n",
        "              #  df[f'ratio_pct_change_{frame}_{group}_{stock}', stock] = df[f'pct_change_{frame}_Industry', stock] / df[f'pct_change_{frame}_Sector', stock]\n",
        "\n",
        "            for measure in measures_tickers: #measures & indexses & stock with measures ratios\n",
        "              if measure == '^VIX':\n",
        "                continue\n",
        "\n",
        "              df[f'ratio_pct_change_{frame}_{measure}', stock] = df[f'pct_change_{frame}', stock] / df[f'pct_change_{frame}_{measure}', stock]\n",
        "\n",
        "              for group in groups:\n",
        "                  df[f'ratio_pct_change_{frame}_{measure}_{group}', stock] = df[f'pct_change_{frame}_{group}', stock] / df[f'pct_change_{frame}_{measure}', stock]\n",
        "        if i%100 == 0:\n",
        "          print(i,'finished')\n",
        "    return df,removed_stocks\n",
        "\n",
        "sentimant_df,removed_stocks = preprocess_sentiment(df=data, start_time=Start_date ,end_time=End_date,measures_tickers=measures_tickers,stocks_list=all_symbols,industry_dict=industry_dict,sector_dict=sector_dict,all_stocks_data=stock_info_df)\n",
        "for s in removed_stocks:\n",
        "    all_symbols.remove(s)\n",
        "len(all_symbols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABvD4T01YtST",
        "outputId": "444a8370-c7b6-4afb-deb5-5f137d422a95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 finished\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-8e180421cb9f>:129: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[stock, \"atr_short\"] = tb.ATR(High_stock, Low_stock, adj_close_stock, timeperiod=short_ind)\n",
            "<ipython-input-7-8e180421cb9f>:130: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[stock, \"atr_medium\"] = tb.ATR(High_stock, Low_stock, adj_close_stock, timeperiod=medium_ind)\n",
            "<ipython-input-7-8e180421cb9f>:131: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[stock, \"atr_long\"] = tb.ATR(High_stock, Low_stock, adj_close_stock, timeperiod=long_ind)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100 finished\n",
            "200 finished\n",
            "300 finished\n",
            "400 finished\n",
            "500 finished\n",
            "600 finished\n",
            "700 finished\n",
            "800 finished\n",
            "900 finished\n",
            "1000 finished\n",
            "1100 finished\n",
            "1200 finished\n",
            "1300 finished\n",
            "1400 finished\n",
            "1500 finished\n",
            "1600 finished\n",
            "1700 finished\n",
            "1800 finished\n",
            "1900 finished\n",
            "2000 finished\n",
            "2100 finished\n",
            "2200 finished\n",
            "2300 finished\n",
            "2400 finished\n",
            "2500 finished\n",
            "2600 finished\n",
            "2700 finished\n",
            "2800 finished\n",
            "2900 finished\n",
            "3000 finished\n",
            "3100 finished\n",
            "3200 finished\n",
            "3300 finished\n",
            "3400 finished\n",
            "3500 finished\n",
            "3600 finished\n",
            "3700 finished\n",
            "3800 finished\n",
            "3900 finished\n",
            "4000 finished\n",
            "4100 finished\n",
            "4200 finished\n",
            "4300 finished\n"
          ]
        }
      ],
      "source": [
        "import talib as tb\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import hashlib\n",
        "\n",
        "def preprocess_technical_labels(df = pd.DataFrame(), start_time = '2017-01-01', end_time = '2023-12-01',measures_tickers=[],stocks_list=[],all_stocks_data=pd.DataFrame()):\n",
        "    \"\"\"\n",
        "    Preprocesses technical indicators for machine learning.\n",
        "\n",
        "    Args:\n",
        "        df (DataFrame): The input DataFrame containing stock data.\n",
        "        stocks_list (list): List of stock tickers to consider.\n",
        "        all_stocks_data (DataFrame): Additional information about all stocks.\n",
        "\n",
        "    Returns:\n",
        "        DataFrame: Processed DataFrame with added technical indicators.\n",
        "\n",
        "    The preprocess_technical_indicators function takes stock data in the form of a DataFrame ),\n",
        "    along with a list of stock tickers and additional stock information.\n",
        "    It calculates various technical indicators such as Exponential Moving Averages (EMA), Simple Moving Averages (SMA),\n",
        "    Directional Movement Index (ADX), Average Directional Index (ADI), and more for each stock in the provided list.\n",
        "\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "    df.columns = df.columns.swaplevel(0, 1) #fix columns name\n",
        "\n",
        "    short_ind = 26\n",
        "    medium_ind = 50\n",
        "    long_ind = 200\n",
        "\n",
        "    # Define the intervals for weekly and monthly data\n",
        "    weekly_interval = 5\n",
        "    monthly_interval = 26\n",
        "\n",
        "    # Define the bin edges for the present change groups\n",
        "    bin_edges = [-10, -0.1, -0.05, -0.025, 0, 0.025, 0.05, 0.1, 10]\n",
        "    # Define labels for the present change groups\n",
        "    labels = [ 0, 1, 2, 3, 4, 5, 6, 7]\n",
        "\n",
        "    for i, stock in enumerate(stocks_list):\n",
        "\n",
        "        adj_close_stock = df[stock,'Adj Close']\n",
        "        High_stock = df[stock,'High']\n",
        "        Low_stock = df[stock,'Low']\n",
        "        Volume_stock = df[stock,'Volume']\n",
        "        open_Stock = df[stock,'Open']\n",
        "        df[stock, \"ema_short\"] = tb.EMA(adj_close_stock, timeperiod=short_ind)\n",
        "        df[stock, \"ema_medium\"] = tb.EMA(adj_close_stock, timeperiod=medium_ind)\n",
        "        df[stock, \"ema_long\"] = tb.EMA(adj_close_stock, timeperiod=long_ind)\n",
        "\n",
        "        #continue if thers was no high jump monthly in either direction\n",
        "        month_labels = pd.cut(adj_close_stock.pct_change(periods=monthly_interval), bins=bin_edges, labels=labels, right=False)\n",
        "\n",
        "        # Add a new column 'present_change_group' with labels for present change groups\n",
        "        df[stock, 'label_day'] = pd.cut(adj_close_stock.pct_change(), bins=bin_edges, labels=labels, right=False)\n",
        "        df[stock, 'label_week'] = pd.cut(adj_close_stock.pct_change(periods=weekly_interval), bins=bin_edges, labels=labels, right=False)\n",
        "        df[stock, 'label_month'] = month_labels\n",
        "\n",
        "        df[stock, 'pct_change_week'] = adj_close_stock.pct_change(periods=weekly_interval)\n",
        "        df[stock, 'pct_change_month'] = adj_close_stock.pct_change(periods=monthly_interval)\n",
        "\n",
        "\n",
        "        df[stock, 'Industry'] = all_stocks_data.loc[stock, 'Industry' ]\n",
        "        df[stock, 'Sector'] = all_stocks_data.loc[stock, 'Sector' ]\n",
        "        df[stock, 'stock'] = stock\n",
        "\n",
        "      #Technical indicators\n",
        "        # OVERLAP INDICATORS\n",
        "\n",
        "\n",
        "        df[stock, \"dema_short\"] = tb.DEMA(adj_close_stock, timeperiod=short_ind)\n",
        "        df[stock, \"kama_short\"] = tb.KAMA(adj_close_stock, timeperiod=short_ind)\n",
        "        df[stock, \"dema_medium\"] = tb.DEMA(adj_close_stock, timeperiod=medium_ind)\n",
        "        df[stock, \"kama_medium\"] = tb.KAMA(adj_close_stock, timeperiod=medium_ind)\n",
        "        df[stock, \"dema_long\"] = tb.DEMA(adj_close_stock, timeperiod=long_ind)\n",
        "        df[stock, \"kama_long\"] = tb.KAMA(adj_close_stock, timeperiod=long_ind)\n",
        "\n",
        "        df[stock, \"sma_short\"] = tb.SMA(adj_close_stock, timeperiod=short_ind)\n",
        "        df[stock, \"sma_medium\"] = tb.SMA(adj_close_stock, timeperiod=medium_ind)\n",
        "        df[stock, \"sma_long\"] = tb.SMA(adj_close_stock, timeperiod=long_ind)\n",
        "        df[stock, \"sar\"] = tb.SAR(High_stock, Low_stock)\n",
        "\n",
        "        # MOMENTUM INDICATORS\n",
        "        df[stock, \"adx_short\"] = tb.ADX(High_stock, Low_stock, adj_close_stock, timeperiod=short_ind)\n",
        "        df[stock, \"adx_medium\"] = tb.ADX(High_stock, Low_stock, adj_close_stock, timeperiod=medium_ind)\n",
        "        df[stock, \"adx_long\"] = tb.ADX(High_stock, Low_stock, adj_close_stock, timeperiod=long_ind)\n",
        "\n",
        "        df[stock, \"apo_short\"] = tb.APO(adj_close_stock, fastperiod=long_ind, slowperiod=short_ind)\n",
        "        df[stock, \"apo_medium\"] = tb.APO(adj_close_stock, fastperiod=long_ind, slowperiod=medium_ind)\n",
        "        df[stock, \"apo_long\"] = tb.APO(adj_close_stock, fastperiod=long_ind, slowperiod=long_ind)\n",
        "\n",
        "        df[stock, \"cci_short\"] = tb.CCI(High_stock, Low_stock, adj_close_stock, timeperiod=short_ind)\n",
        "        df[stock, \"cci_medium\"] = tb.CCI(High_stock, Low_stock, adj_close_stock, timeperiod=medium_ind)\n",
        "        df[stock, \"cci_long\"] = tb.CCI(High_stock, Low_stock, adj_close_stock, timeperiod=long_ind)\n",
        "\n",
        "        df[stock, \"bop\"] = tb.BOP(open_Stock, High_stock, Low_stock, adj_close_stock)\n",
        "        df[stock, \"macd\"], df[stock,\"macdsignal\"], df[stock,\"macdhist\"] = tb.MACD(adj_close_stock, fastperiod=12, slowperiod=26, signalperiod=9)\n",
        "\n",
        "        df[stock, \"mfi_short\"] = tb.MFI(High_stock, Low_stock, adj_close_stock, Volume_stock, timeperiod=short_ind)\n",
        "        df[stock, \"mom_short\"] = tb.MOM(adj_close_stock, timeperiod=short_ind)\n",
        "        df[stock, \"mfi_medium\"] = tb.MFI(High_stock, Low_stock, adj_close_stock, Volume_stock, timeperiod=medium_ind)\n",
        "        df[stock, \"mom_medium\"] = tb.MOM(adj_close_stock, timeperiod=medium_ind)\n",
        "        df[stock, \"mfi_long\"] = tb.MFI(High_stock, Low_stock, adj_close_stock, Volume_stock, timeperiod=long_ind)\n",
        "        df[stock, \"mom_long\"] = tb.MOM(adj_close_stock, timeperiod=long_ind)\n",
        "\n",
        "        df[stock, \"rsi_short\"] = tb.RSI(adj_close_stock, timeperiod=short_ind)\n",
        "        df[stock, \"rsi_medium\"] = tb.RSI(adj_close_stock, timeperiod=medium_ind)\n",
        "        df[stock, \"rsi_long\"] = tb.RSI(adj_close_stock, timeperiod=long_ind)\n",
        "\n",
        "        # VOLUME INDICATORS\n",
        "        df[stock, \"ad\"] = tb.AD(High_stock, Low_stock, adj_close_stock, Volume_stock)\n",
        "        df[stock, \"adosc_short\"] = tb.ADOSC(High_stock, Low_stock, adj_close_stock, Volume_stock, fastperiod=short_ind, slowperiod=short_ind)\n",
        "        df[stock, \"adosc_medium\"] = tb.ADOSC(High_stock, Low_stock, adj_close_stock, Volume_stock, fastperiod=short_ind, slowperiod=medium_ind)\n",
        "        df[stock, \"adosc_long\"] = tb.ADOSC(High_stock, Low_stock, adj_close_stock, Volume_stock, fastperiod=short_ind, slowperiod=long_ind)\n",
        "\n",
        "        df[stock, \"obv\"] = tb.OBV(adj_close_stock, Volume_stock)\n",
        "        df[stock, \"trange\"] = tb.TRANGE(High_stock, Low_stock, adj_close_stock)\n",
        "        df[stock, \"atr_short\"] = tb.ATR(High_stock, Low_stock, adj_close_stock, timeperiod=short_ind)\n",
        "        df[stock, \"atr_medium\"] = tb.ATR(High_stock, Low_stock, adj_close_stock, timeperiod=medium_ind)\n",
        "        df[stock, \"atr_long\"] = tb.ATR(High_stock, Low_stock, adj_close_stock, timeperiod=long_ind)\n",
        "\n",
        "        df.index = pd.to_datetime(df.index)\n",
        "\n",
        "        # Calculate 52-week high and low\n",
        "        df['year'] = df.index.year\n",
        "        df['month'] = df.index.month\n",
        "        df['day'] = df.index.day\n",
        "\n",
        "        if i%100 == 0:\n",
        "          print(i,'finished')\n",
        "    return df\n",
        "\n",
        "sentimant_df.dropna(axis=0,inplace=True,how=\"all\")\n",
        "sentimant_df.dropna(axis=1,inplace=True,how=\"all\")\n",
        "ta_sentimant_df_new = preprocess_technical_labels(df=sentimant_df,measures_tickers=measures_tickers,stocks_list=all_symbols,all_stocks_data=stock_info_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aGLaWJr7l98Q"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "def t_df_labels(label_type = 'label_week',df = pd.DataFrame(),stocks_list = []):# Shifts back the labels for each time lapce\n",
        "    df = df.copy()\n",
        "    df_working = pd.DataFrame()\n",
        "    stocks_number = len(stocks_list)\n",
        "    count = 0\n",
        "    df_nan_values_day = pd.DataFrame({'label_day': [np.nan] })\n",
        "    df_nan_values_week = pd.DataFrame({label_type: [np.nan] * 5})\n",
        "    df_nan_values_month = pd.DataFrame({'label_month': [np.nan] * 20})\n",
        "    date_col = df.index\n",
        "\n",
        "    for i,stock in enumerate(stocks_list):\n",
        "      stock_df = df[stock]\n",
        "      stock_df['Symbol'] = stock\n",
        "      stock_df['date'] = date_col\n",
        "      if label_type in stock_df.columns:\n",
        "          df_day = pd.concat([pd.DataFrame({'label_day': stock_df['label_day'][1:] }), df_nan_values_day], ignore_index=True)\n",
        "          df_day.index = stock_df.index\n",
        "          stock_df['label_day'] = df_day\n",
        "\n",
        "          df_week = pd.concat([pd.DataFrame({label_type: stock_df[label_type][5:] }), df_nan_values_week], ignore_index=True)\n",
        "          df_week.index = stock_df.index\n",
        "          stock_df[label_type] = df_week\n",
        "          df_week_pct_change = pd.concat([pd.DataFrame({'pct_change_week': stock_df['pct_change_week'][5:] }), df_nan_values_week], ignore_index=True)\n",
        "          df_week_pct_change.index = stock_df.index\n",
        "          stock_df['pct_change_week'] = df_week_pct_change['pct_change_week']\n",
        "\n",
        "          df_month = pd.concat([pd.DataFrame({'label_month': stock_df['label_month'][20:] }), df_nan_values_month], ignore_index=True)\n",
        "          df_month.index = stock_df.index\n",
        "          stock_df['label_month'] = df_month\n",
        "          df_month_pct_change = pd.concat([pd.DataFrame({'pct_change_month': stock_df['pct_change_month'][20:] }), df_nan_values_month], ignore_index=True)\n",
        "          df_month_pct_change.index = stock_df.index\n",
        "          stock_df['pct_change_month'] = df_month_pct_change['pct_change_month']\n",
        "\n",
        "          stock_df.reset_index(drop=True, inplace=True)\n",
        "          df_working = pd.concat([df_working, stock_df], ignore_index=True)\n",
        "      else:\n",
        "          count+=1\n",
        "    print(count,'dont have label',df_working)\n",
        "    return df_working\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHbjetnIdLdy"
      },
      "outputs": [],
      "source": [
        "working_df_updated_new = t_df_labels(label_type = 'label_week',df = ta_sentimant_df_new,stocks_list = all_symbols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYcTWs98DCS1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Initialize a LabelEncoder\n",
        "columns_drop_withNan = ['Adj Close',\"ema_long\",\"mom_long\"]\n",
        "working_df_updated_new1 =  working_df_updated_new.dropna(subset=columns_drop_withNan)\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Apply Label Encoding to each column\n",
        "working_df_updated_new1['Industry_encoded'] = label_encoder.fit_transform(working_df_updated_new1['Industry'])#encode strings features\n",
        "working_df_updated_new1['Sector_encoded'] = label_encoder.fit_transform(working_df_updated_new1['Sector'])\n",
        "working_df_updated_new1.to_csv('/content/drive/MyDrive/stocks_data/Consecutive_stocks.csv', index=False)"
      ]
    }
  ]
}